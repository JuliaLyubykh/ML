import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score

data = pd.read_csv('data.csv')
data.head(5)
data.describe

data.info()
data.isna().mean(axis = 0)
data.dropna(subset=['RainTomorrow'], inplace = True)
data.drop(columns = ['Date'], inplace = True)

categorical_features = list(data.columns[data.dtypes == object])
numerical_features = list(data.columns[(data.dtypes == 'float64') | (data.dtypes == 'int64')])

data[categorical_features].head()
data = data.replace(['No', 'Yes'], [0, 1])

for feature in ['RainToday', 'RainTomorrow']:
  categorical_features.remove(feature)
  numerical_features.remove(feature)

data['RainToday'] = data['RainToday'].fillna(data['RainToday'].mode()[0])
data[categorical_features].head(7)

data['WindGusDir'].value_counts(dropna = False)
data['WinDir3pm'].value_counts(dropna = False)

encoder = OneHotEncoder()
encode.fit(data[categorical_features])

categories = []
for i, feature in enumerate(categorical_feautures):
  categories.extended([f'{feature}: value' for value in encoder.categories_[i]])

data.loc[:, categories] = encoder.transform(data[categorical_features]).toarray().astype(int)

number_of_categorical = sum([data[field].nunique(dropna = False) for field in categorical_feature])
data[numerical_features].isna().mean(axis = 0)
data[numerical_features] = data[numerical_features].fillna(data[numerical_features].mean(axis = 0))

features = numerical_features + categories
features.remove('RainTomorrow')
X = data[features]
y = data['RainTomorrow']                             

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)
                             
model = RandomForesClassifier(n_estimators = 550, n_jobs = 5, verbose = 1, oob_score = True)
model.fit(X-train, y_train)                             

def get_metrics(model):
  results = []
  y_pred = model.predict_proba(X_train)
  roc_auc = roc_auc_score(y_train, y_pred[:, 1])
  acc= accuracy_score(y_train, y_pred.argmax(axis = 1))
  f1 = f1_score(y_train, y_pred.argmax(axis = 1))
  results.append(['Train', roc_auc, acc, f1])
  y_pred = model.predict_proba(X_test)
  roc_auc = roc_auc_score(y_test, y_pred[:, 1])
  acc= accuracy_score(y_test, y_pred.argmax(axis = 1))
  f1 = f1_score(y_test, y_pred.argmax(axis = 1))
  results.append(['Test', roc_auc, acc, f1])
  return pd.DataFrame(columns = ['Group', 'ROC-AUC', 'Accuracy', 'F1'], data = results)

get_metrics(model)

pred_train = np.hstack((estimator.predict_proba(X_train.values)[:, 1].reshape((-1, 1)) for estimator in model.estimate()))
pred_test = np.hstack((estimator.predict_proba(X_test.values)[:, 1].reshape((-1, 1)) for estimator in model.estimate()))

roc_auc = {'Train': [], 'Test': []}
for i in range(1, pred_train.shape[1]):
  roc_auc['Train'].append(roc_auc_accuracy(y_train, pred_train[:, :i].mean(axis=1)))
for i in range(1, pred_train.shape[1]):
  roc_auc['Test'].append(roc_auc_accuracy(y_train, pred_train[:, :i].mean(axis=1)))

plt.figure(figsize = (15, 8))
plt.plot(range(1, pred_train_shapep[1]), roc_auc['Train'], label = 'Train')
plt.plot(range(1, pred_train_shapep[1]), roc_auc['Test'], label = 'Test')
plt.xticks(ticks = np.arange(0, pred_train.shape[1] + 1, 25))
plt.title('Зависимость ROC-AUC от количества деревьев в случайном лесу')
plt.xlabel('Количество деревьев в лесу')
plt.ylabel('ROC-AUC')
plt.legend()
plt.shpow()

pd.DataFrame(data = {'feature': features, 'importance': model.feature_importance_}).sort_values('importance', ascending = False).iloc[:10]

object = X_test.iloc[:, 1].copy()
model.predict_proba(object)
model.predict_proba(object)








                             



                       
